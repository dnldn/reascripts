NOTE: This program doesn't work on 32-bit audio; which may be the default in reaper when you glue or record material. Access your project settings (alt-enter is the hotkey by default), go to the media tab, and set format for apply fx/glue/freeze/etc to 24-bit if you need to render material before you perform analysis.

---------------------------------------------------------------------------------

Methods:

HFC:
This method computes the high frequency content of the input spectral frame. Efficient at detecting percussion and material with sharply-defined transients; results may vary with less transient-forward material like strings.

	*Paul Masri. Computer modeling of Sound for Transformation and Synthesis of
	Musical Signal. PhD dissertation, University of Bristol, UK, 1996.

Energy:
This function calculates the local energy of the input spectral frame. Similar results to HFC; makes detections more aggressively because it isn't filtered as much toward high frequencies. Most aggressive of the algorithms by number of detections by a fair amount.

Phase:
This function uses information in both frequency and phase to determine changes in the spectral content that might correspond to musical onsets. It is best suited for complex signals such as polyphonic recordings. Targeted more toward pitch changes than peaks. Least aggressive of the algorithms by number of detections by a fair amount.

	*Juan-Pablo Bello, Mike P. Davies, and Mark B. Sandler.  Phase-based note
	onset detection for music signals. In Proceedings of the IEEE International
	Conference on Acoustics Speech and Signal Processing, pages 441­444,
	Hong-Kong, 2003.

Complex:
This function uses information both in frequency and in phase to determine changes in the spectral content that might correspond to musical onsets. It is best suited for complex signals such as polyphonic recordings. Fairly similar results to HFC, with timing being slightly displaced and fewer detections in spots with no pitch change. If HFC isn't splitting in the exact right spot on pitched material, try this one.

	*Christopher Duxbury, Mike E. Davies, and Mark B. Sandler.  Complex domain
	onset detection for musical signals. In Proceedings of the Digital Audio
	Effects Conference, DAFx-03, pages 90-93, London, UK, 2003.

Spectral difference: 
This function works on a principle of estimating tempo, then making slices based on predicted beats where the spectral content is similar. The splits it will predict are based on rhythmic similarities within the audio file and not based on spectral spikes, so you may get better results using this to chop material to a sampler.

	*Jonathan Foote and Shingo Uchihashi. The beat spectrum: a new approach to
	rhythm analysis. In IEEE International Conference on Multimedia and Expo
	(ICME 2001), pages 881­884, Tokyo, Japan, August 2001.

Spectral flux:
This function uses phase deviation and flux in magnitude between short time fourier transform bins to calculate transient position. Positioning is slightly earlier on this one compared to the other detection functions; may be more appropriate for instruments where there is a little bit of buildup before the peak in the note (guitar, shakers, hi-hats etc)

	*Simon Dixon, Onset Detection Revisited, in ``Proceedings of the 9th
	International Conference on Digital Audio Effects'' (DAFx-06), Montreal,
	Canada, 2006.

Kulback-Liebler:
This one's over my head. It seems to be based on splitting a band with STFT's and doing harmonic analysis, so you can pick up onset spots based on energy variation. Couldn't find a great use case for it because the other algorithms pick up low-level changes as long as the silence threshold is set low enough.

	*Stephen Hainsworth and Malcom Macleod. Onset detection in music audio
	signals. In Proceedings of the International Computer Music Conference
	(ICMC), Singapore, 2003.

Modified Kulback-Liebler: 
Similar to above, but more aggressive in number of detections and the output timing is a little different.

	*Paul Brossier, ``Automatic annotation of musical audio for interactive
	systems'', Chapter 2, Temporal segmentation, PhD thesis, Centre for
	Digital music, Queen Mary University of London, London, UK, 2006.  

---------------------------------------------------------------------------------

Hop size: The number of samples between two consecutive analyses. Defaults to 256.

---------------------------------------------------------------------------------

Gate threshold: Sets the silence threshold in dB, under which the onsets will not be detected. Anything under -20 eliminates anything that isn't a very loud peak.

---------------------------------------------------------------------------------

Interval (ms): Sets the minimum inter-onset interval in ms; the shortest possible interval between two consecutive detections. Defaults to 50.